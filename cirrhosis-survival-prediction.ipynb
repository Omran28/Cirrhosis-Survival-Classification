{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97315,"databundleVersionId":11578039,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import os\n\n# if os.path.exists(\"submission.csv\"):\n#     os.remove(\"submission.csv\")\n\n# if os.path.exists(\"best_model.pth\"):\n#     os.remove(\"best_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:19.922896Z","iopub.execute_input":"2025-08-24T20:32:19.923158Z","iopub.status.idle":"2025-08-24T20:32:19.926872Z","shell.execute_reply.started":"2025-08-24T20:32:19.923141Z","shell.execute_reply":"2025-08-24T20:32:19.926099Z"}},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom scipy.stats import spearmanr\nfrom scipy import stats\nfrom scipy.stats import boxcox\n\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nfrom sklearn import preprocessing\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:19.928437Z","iopub.execute_input":"2025-08-24T20:32:19.928689Z","iopub.status.idle":"2025-08-24T20:32:19.944877Z","shell.execute_reply.started":"2025-08-24T20:32:19.928667Z","shell.execute_reply":"2025-08-24T20:32:19.944116Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"# Load datasets","metadata":{}},{"cell_type":"code","source":"train_dataset = pd.read_csv(\"/kaggle/input/nti-r-1-beyond/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/nti-r-1-beyond/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:19.946020Z","iopub.execute_input":"2025-08-24T20:32:19.946282Z","iopub.status.idle":"2025-08-24T20:32:20.017884Z","shell.execute_reply.started":"2025-08-24T20:32:19.946261Z","shell.execute_reply":"2025-08-24T20:32:20.017345Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"# Preprocessing Functions","metadata":{}},{"cell_type":"markdown","source":"**One Hot Encoding**","metadata":{}},{"cell_type":"code","source":"def one_hot_encoding(dataset, cols):\n    for col in cols:\n        dummies = pd.get_dummies(dataset[col], prefix=col).astype(int)\n        dataset = dataset.drop(columns=[col])\n        dataset = pd.concat([dataset, dummies], axis=1)\n    \n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.018560Z","iopub.execute_input":"2025-08-24T20:32:20.018763Z","iopub.status.idle":"2025-08-24T20:32:20.023399Z","shell.execute_reply.started":"2025-08-24T20:32:20.018747Z","shell.execute_reply":"2025-08-24T20:32:20.022565Z"}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"**Label Encoding**","metadata":{}},{"cell_type":"code","source":"def label_encoding(train_df, val_df, target_col):\n    label_encoder = LabelEncoder()\n    \n    train_df[target_col] = label_encoder.fit_transform(train_df[target_col]).astype(int)\n    val_df[target_col]   = label_encoder.transform(val_df[target_col]).astype(int)\n    \n    return train_df, val_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.025232Z","iopub.execute_input":"2025-08-24T20:32:20.025517Z","iopub.status.idle":"2025-08-24T20:32:20.042467Z","shell.execute_reply.started":"2025-08-24T20:32:20.025493Z","shell.execute_reply":"2025-08-24T20:32:20.041940Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"**Check the distribution and outliers**","metadata":{}},{"cell_type":"code","source":"def outliers_check(dataset, col):\n    print(f\"--- Summary for {col} ---\")\n    print(dataset[col].describe())\n\n    # Detect outliers using IQR\n    Q1 = dataset[col].quantile(0.25)\n    Q3 = dataset[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n\n    lower_outliers = dataset[col] < lower_bound\n    upper_outliers = dataset[col] > upper_bound\n    outliers = dataset[lower_outliers | upper_outliers]\n\n    # Print thresholds and counts\n    print(f\"\\nLower bound: {lower_bound:.3f}\")\n    print(f\"Upper bound: {upper_bound:.3f}\")\n\n    # View Outliers\n    print(f\"\\nTotal number of outliers: {outliers.shape[0]}\")\n    lower_vals = np.sort(dataset.loc[lower_outliers, col].values)\n    upper_vals = np.sort(dataset.loc[upper_outliers, col].values)\n\n    if not outliers.empty:\n        print(f\"Lower Outliers ({len(lower_vals)}): {lower_vals}\")\n        print(f\"Upper Outliers ({len(upper_vals)}): {upper_vals}\")\n\n    # Skewness check\n    print(f\"Skewness ({col}): {dataset[col].skew()}\\n\")\n\n    # Plot distribution\n    plt.figure(figsize=(10, 4))\n    sns.histplot(dataset[col], bins=30, kde=True, color='skyblue')\n    plt.title(f'{col} Distribution')\n    plt.xlabel(col)\n    plt.ylabel('Count')\n    plt.show()\n\n    # Plot boxplot\n    plt.figure(figsize=(6, 4))\n    sns.boxplot(x=dataset[col], color='lightgreen')\n    plt.title(f'{col} Boxplot')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.043125Z","iopub.execute_input":"2025-08-24T20:32:20.043354Z","iopub.status.idle":"2025-08-24T20:32:20.066404Z","shell.execute_reply.started":"2025-08-24T20:32:20.043338Z","shell.execute_reply":"2025-08-24T20:32:20.065679Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"**Log Transformation**","metadata":{}},{"cell_type":"code","source":"def log_transform(train_df, val_df, test_df, cols):\n    shifts = {col: abs(train_df[col].min()) + 1 if train_df[col].min() <= 0 else 0\n              for col in cols}\n\n    for col in cols:\n        train_df[col] = np.log1p(train_df[col] + shifts[col])\n        val_df[col]   = np.log1p(val_df[col]   + shifts[col])\n        test_df[col]  = np.log1p(test_df[col]  + shifts[col])\n\n    return train_df, val_df, test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.067365Z","iopub.execute_input":"2025-08-24T20:32:20.067703Z","iopub.status.idle":"2025-08-24T20:32:20.089488Z","shell.execute_reply.started":"2025-08-24T20:32:20.067680Z","shell.execute_reply":"2025-08-24T20:32:20.088793Z"}},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"**Boxcox train transformation**","metadata":{}},{"cell_type":"code","source":"def boxcox_train(dataset, cols):\n    fitted_lambdas = {}\n    shifts = {}\n    \n    for col in cols:\n        min_val = dataset[col].min()\n        shift = abs(min_val) + 1 if min_val <= 0 else 0\n        data_to_transform = dataset[col] + shift\n        \n        transformed, fitted_lambda = boxcox(data_to_transform)\n        dataset[col] = transformed\n        \n        fitted_lambdas[col] = fitted_lambda\n        shifts[col] = shift\n    \n    return dataset, fitted_lambdas, shifts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.090134Z","iopub.execute_input":"2025-08-24T20:32:20.090366Z","iopub.status.idle":"2025-08-24T20:32:20.105744Z","shell.execute_reply.started":"2025-08-24T20:32:20.090351Z","shell.execute_reply":"2025-08-24T20:32:20.104983Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"**Boxcox test/val transformation**","metadata":{}},{"cell_type":"code","source":"def boxcox_apply(dataset, cols, fitted_lambdas, shifts):\n    for col in cols:\n        dataset[col] = boxcox(dataset[col] + shifts[col], lmbda=fitted_lambdas[col])\n    return dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.108355Z","iopub.execute_input":"2025-08-24T20:32:20.108553Z","iopub.status.idle":"2025-08-24T20:32:20.127895Z","shell.execute_reply.started":"2025-08-24T20:32:20.108538Z","shell.execute_reply":"2025-08-24T20:32:20.127082Z"}},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":"**Compare skewness between similar 2 columns**","metadata":{}},{"cell_type":"code","source":"def compare_skewness(dataset, col, new_col):\n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    dataset[col].hist(bins=50)\n    plt.title(f\"Original {col}\")\n\n    plt.subplot(1, 2, 2)\n    dataset[new_col].hist(bins=50)\n    plt.title(new_col)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.128640Z","iopub.execute_input":"2025-08-24T20:32:20.128867Z","iopub.status.idle":"2025-08-24T20:32:20.144123Z","shell.execute_reply.started":"2025-08-24T20:32:20.128852Z","shell.execute_reply":"2025-08-24T20:32:20.143632Z"}},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":"**Iterative Imputing**","metadata":{}},{"cell_type":"code","source":"def fit_predictive_imputer(df, random_state=42):\n    df_imputed = df.copy()\n    numeric_cols = df_imputed.select_dtypes(include='number').columns\n    cat_cols = df_imputed.select_dtypes(include='object').columns\n    \n    # Numeric imputer\n    num_imputer = IterativeImputer(\n    estimator=RandomForestRegressor(n_estimators=100, random_state=random_state, n_jobs=-1),\n    max_iter=10,\n    random_state=random_state\n    )\n\n    if len(numeric_cols) > 0:\n        df_imputed[numeric_cols] = num_imputer.fit_transform(df_imputed[numeric_cols])\n    \n    # Categorical imputers\n    cat_imputer_dict = {}\n    for col in cat_cols:\n        df_imputed[col] = df_imputed[col].astype('category')\n        df_imputed[col] = df_imputed[col].cat.codes  # NaNs -> -1\n\n        cat_imputer = IterativeImputer(\n        estimator=RandomForestRegressor(n_estimators=100, random_state=random_state, n_jobs=-1),\n        max_iter=10,\n        random_state=random_state\n        )\n\n        df_imputed[[col]] = cat_imputer.fit_transform(df_imputed[[col]])\n        cat_imputer_dict[col] = cat_imputer\n\n        # Convert back to original categories\n        codes = df_imputed[col].round().astype(int)\n        categories = df[col].astype('category').cat.categories\n        codes = codes.clip(0, len(categories)-1)\n        df_imputed[col] = pd.Categorical.from_codes(codes, categories=categories)\n    \n    return df_imputed, num_imputer, cat_imputer_dict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.144852Z","iopub.execute_input":"2025-08-24T20:32:20.145032Z","iopub.status.idle":"2025-08-24T20:32:20.162326Z","shell.execute_reply.started":"2025-08-24T20:32:20.145018Z","shell.execute_reply":"2025-08-24T20:32:20.161632Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def transform_predictive_imputer(df, num_imputer, cat_imputer_dict):\n    df_imputed = df.copy()\n    numeric_cols = df_imputed.select_dtypes(include='number').columns\n    cat_cols = df_imputed.select_dtypes(include='object').columns\n\n    # Numeric\n    if len(numeric_cols) > 0:\n        df_imputed[numeric_cols] = num_imputer.transform(df_imputed[numeric_cols])\n\n    # Categorical\n    for col in cat_cols:\n        df_imputed[col] = df_imputed[col].astype('category').cat.codes\n        cat_imputer = cat_imputer_dict[col]\n        df_imputed[[col]] = cat_imputer.transform(df_imputed[[col]])\n        # Convert back to original categories\n        codes = df_imputed[col].round().astype(int)\n        categories = df[col].astype('category').cat.categories\n        codes = codes.clip(0, len(categories)-1)\n        df_imputed[col] = pd.Categorical.from_codes(codes, categories=categories)\n    \n    return df_imputed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.163044Z","iopub.execute_input":"2025-08-24T20:32:20.163314Z","iopub.status.idle":"2025-08-24T20:32:20.192120Z","shell.execute_reply.started":"2025-08-24T20:32:20.163292Z","shell.execute_reply":"2025-08-24T20:32:20.191603Z"}},"outputs":[],"execution_count":67},{"cell_type":"markdown","source":"# Features Analysis","metadata":{}},{"cell_type":"markdown","source":"**Heatmap**","metadata":{}},{"cell_type":"code","source":"# import seaborn as sns\n# import matplotlib.pyplot as plt\n\n# # Assume corr_matrix is your full correlation matrix from previous step\n# plt.figure(figsize=(12, 10))\n\n# # Use mask for upper triangle (optional)\n# mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n\n# # Plot heatmap\n# sns.heatmap(\n#     corr_matrix.astype(float),\n#     annot=True,\n#     fmt=\".2f\",\n#     cmap=\"coolwarm\",\n#     mask=mask,\n#     cbar_kws={'label': 'Correlation'},\n#     square=True\n# )\n\n# plt.title(\"Full Correlation Matrix (Numeric + Categorical)\")\n# plt.tight_layout()\n# plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.192805Z","iopub.execute_input":"2025-08-24T20:32:20.193002Z","iopub.status.idle":"2025-08-24T20:32:20.216563Z","shell.execute_reply.started":"2025-08-24T20:32:20.192987Z","shell.execute_reply":"2025-08-24T20:32:20.215751Z"},"_kg_hide-output":true},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"**Drug**","metadata":{}},{"cell_type":"code","source":"def Drug_Analysis(dataset):\n    dataset['Drug'].fillna(\"Unknown\", inplace=True)\n    # print(dataset['Drug'].value_counts(dropna=False))\n    # print(pd.crosstab(dataset['Drug'], dataset['Status'], normalize='index')) # Check Corr with target\n    dataset = one_hot_encoding(dataset, \"Drug\")\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.217530Z","iopub.execute_input":"2025-08-24T20:32:20.218221Z","iopub.status.idle":"2025-08-24T20:32:20.236082Z","shell.execute_reply.started":"2025-08-24T20:32:20.218172Z","shell.execute_reply":"2025-08-24T20:32:20.235092Z"}},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":"**Age**","metadata":{}},{"cell_type":"code","source":"def Age_Analysis(dataset):\n    dataset['Age'] = dataset['Age'] / 365\n    dataset['Age'] = dataset['Age'].clip(upper=84.405)\n    dataset, colm, _ = boxcox_transform(dataset, \"Age\", False)\n    # outliers_check(dataset, \"Age\")\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.237052Z","iopub.execute_input":"2025-08-24T20:32:20.237304Z","iopub.status.idle":"2025-08-24T20:32:20.252059Z","shell.execute_reply.started":"2025-08-24T20:32:20.237284Z","shell.execute_reply":"2025-08-24T20:32:20.251492Z"}},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"**Sex**","metadata":{}},{"cell_type":"code","source":"def Sex_Analysis(dataset):\n    # print(dataset[\"Sex\"].value_counts())\n\n    dataset = one_hot_encoding(dataset, \"Sex\")\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.252728Z","iopub.execute_input":"2025-08-24T20:32:20.252967Z","iopub.status.idle":"2025-08-24T20:32:20.279660Z","shell.execute_reply.started":"2025-08-24T20:32:20.252948Z","shell.execute_reply":"2025-08-24T20:32:20.279108Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"**Ascites**","metadata":{}},{"cell_type":"code","source":"def Ascites_Analysis(dataset):\n    dataset['Ascites'].fillna(\"Unknown\", inplace=True)\n    # print(dataset['Ascites'].value_counts(dropna=False))\n    # print(pd.crosstab(dataset['Ascites'], dataset['Status'], normalize='index')) # Check Corr with target\n    dataset = one_hot_encoding(dataset, \"Ascites\")\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.280438Z","iopub.execute_input":"2025-08-24T20:32:20.280640Z","iopub.status.idle":"2025-08-24T20:32:20.294345Z","shell.execute_reply.started":"2025-08-24T20:32:20.280623Z","shell.execute_reply":"2025-08-24T20:32:20.293794Z"}},"outputs":[],"execution_count":72},{"cell_type":"markdown","source":"**Hepatomegaly**","metadata":{}},{"cell_type":"code","source":"def Hepatomegaly_Analysis(dataset):\n    # print(dataset['Hepatomegaly'].value_counts(dropna=False))    \n    dataset['Hepatomegaly'] = dataset['Hepatomegaly'].replace('S', dataset['Hepatomegaly'].mode()[0])\n    # print(pd.crosstab(dataset['Hepatomegaly'], dataset['Status'], normalize='index')) # Check Corr with target\n    dataset = one_hot_encoding(dataset, \"Hepatomegaly\")\n    return dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.295019Z","iopub.execute_input":"2025-08-24T20:32:20.295258Z","iopub.status.idle":"2025-08-24T20:32:20.312084Z","shell.execute_reply.started":"2025-08-24T20:32:20.295231Z","shell.execute_reply":"2025-08-24T20:32:20.311562Z"}},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"**Spiders**","metadata":{}},{"cell_type":"code","source":"def Spiders_Analysis(dataset):\n    dataset['Spiders'].fillna(\"Unknown\", inplace=True)\n    # print(dataset['Spiders'].value_counts(dropna=False))\n    \n    # Check Corr with target\n    # print(pd.crosstab(dataset['Spiders'], dataset['Status'], normalize='index'))\n    dataset = one_hot_encoding(dataset, \"Spiders\")\n    return dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.312831Z","iopub.execute_input":"2025-08-24T20:32:20.313023Z","iopub.status.idle":"2025-08-24T20:32:20.329939Z","shell.execute_reply.started":"2025-08-24T20:32:20.313009Z","shell.execute_reply":"2025-08-24T20:32:20.329426Z"}},"outputs":[],"execution_count":74},{"cell_type":"markdown","source":"**Edema**","metadata":{}},{"cell_type":"code","source":"def Edema_Analysis(dataset):\n    # print(dataset['Edema'].value_counts())\n    # print(pd.crosstab(dataset['Edema'], dataset['Status'], normalize='index')) # Check Corr with target\n    edema_map = {\"N\": 0, \"S\": 1, \"Y\": 2}\n    dataset['Edema'] = dataset['Edema'].map(edema_map)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.333759Z","iopub.execute_input":"2025-08-24T20:32:20.333953Z","iopub.status.idle":"2025-08-24T20:32:20.347476Z","shell.execute_reply.started":"2025-08-24T20:32:20.333934Z","shell.execute_reply":"2025-08-24T20:32:20.346898Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"**Bilirubin**","metadata":{}},{"cell_type":"code","source":"def Bilirubin_Analysis(dataset):\n    # outliers_check(dataset, \"Bilirubin\")\n    dataset, new_col, _ = boxcox_transform(dataset, \"Bilirubin\", False)\n    # outliers_check(dataset, new_col)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.348208Z","iopub.execute_input":"2025-08-24T20:32:20.348412Z","iopub.status.idle":"2025-08-24T20:32:20.365700Z","shell.execute_reply.started":"2025-08-24T20:32:20.348397Z","shell.execute_reply":"2025-08-24T20:32:20.365137Z"}},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":"**Cholesterol**","metadata":{}},{"cell_type":"code","source":"def Cholesterol_Analysis(dataset):\n    dataset['Cholesterol_missing'] = dataset['Cholesterol'].isna().astype(int) # Missing flag\n    # outliers_check(dataset, \"Cholesterol\")\n\n    # # Impute with KNN\n    # if fit:  # Training set\n    #     imputer = KNNImputer(n_neighbors=5)\n    #     dataset[['Cholesterol']] = imputer.fit_transform(dataset[['Cholesterol']])\n    # else:    # Test set\n    #     dataset[['Cholesterol']] = imputer.transform(dataset[['Cholesterol']])\n\n    dataset, new_col, _ = boxcox_transform(dataset, \"Cholesterol\", False)\n    # outliers_check(dataset, new_col)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.366370Z","iopub.execute_input":"2025-08-24T20:32:20.366529Z","iopub.status.idle":"2025-08-24T20:32:20.385277Z","shell.execute_reply.started":"2025-08-24T20:32:20.366516Z","shell.execute_reply":"2025-08-24T20:32:20.384644Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"**Albumin**","metadata":{}},{"cell_type":"code","source":"def Albumin_Analysis(dataset):\n    # outliers_check(dataset, \"Albumin\")\n    dataset, new_col, _ = boxcox_transform(dataset, \"Albumin\", False)\n    # outliers_check(dataset, new_col)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.386094Z","iopub.execute_input":"2025-08-24T20:32:20.386711Z","iopub.status.idle":"2025-08-24T20:32:20.407899Z","shell.execute_reply.started":"2025-08-24T20:32:20.386686Z","shell.execute_reply":"2025-08-24T20:32:20.407313Z"}},"outputs":[],"execution_count":78},{"cell_type":"markdown","source":"**Copper**","metadata":{}},{"cell_type":"code","source":"def Copper_Analysis(dataset, target=\"Status\"):\n    dataset['Copper_missing'] = dataset['Copper'].isna().astype(int)  # Missing flag\n\n    # Impute Copper with KNN\n    # if fit:  # training set\n    #     imputer = KNNImputer(n_neighbors=5)\n    #     dataset[['Copper']] = imputer.fit_transform(dataset[['Copper']])\n    # else:    # test set\n    #     dataset[['Copper']] = imputer.transform(dataset[['Copper']])\n\n    # Check relation with target\n    # groups = [dataset.loc[dataset[target] == t, 'Copper'].dropna() for t in dataset[target].unique()]\n    # stat, p = stats.kruskal(*groups)\n    # print(f\"\\nKruskal-Wallis test for Copper vs {target}: stat={stat:.3f}, p-value={p:.4f}\")\n\n    # Effect size (η²)\n    # n_total = sum(len(g) for g in groups)\n    # eta_sq = stat / (n_total - 1)\n    # print(f\"Effect size η²: {eta_sq:.4f}\")\n\n    # Outlier checks\n    # outliers_check(dataset, \"Copper\")\n    dataset, new_col, _ = boxcox_transform(dataset, \"Copper\", False)\n    # outliers_check(dataset, new_col)\n\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.408779Z","iopub.execute_input":"2025-08-24T20:32:20.409497Z","iopub.status.idle":"2025-08-24T20:32:20.427523Z","shell.execute_reply.started":"2025-08-24T20:32:20.409465Z","shell.execute_reply":"2025-08-24T20:32:20.426626Z"}},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":"**Alk_Phos**","metadata":{}},{"cell_type":"code","source":"def AlkPhos_Analysis(dataset, target=\"Status\"):\n    dataset['AlkPhos_missing'] = dataset['Alk_Phos'].isna().astype(int) # Missing flag\n\n    # KNN imputation\n    # if fit:  # training set\n    #     imputer = KNNImputer(n_neighbors=5)\n    #     dataset[['Alk_Phos']] = imputer.fit_transform(dataset[['Alk_Phos']])\n    # else:  # test set\n    #     dataset[['Alk_Phos']] = imputer.transform(dataset[['Alk_Phos']])\n        \n    # outliers_check(dataset, \"Alk_Phos\")\n    dataset, col, _ = boxcox_transform(dataset, \"Alk_Phos\", False)\n    # outliers_check(dataset, col)\n\n    # Relation with target\n    # groups = [dataset.loc[dataset[target]==t, col] for t in dataset[target].unique()]\n    # stat, p = stats.kruskal(*groups)\n    # print(f\"Kruskal-Wallis test for {col} vs {target}: stat={stat:.3f}, p={p:.4f}\")\n\n    return dataset, col","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.428297Z","iopub.execute_input":"2025-08-24T20:32:20.428527Z","iopub.status.idle":"2025-08-24T20:32:20.445008Z","shell.execute_reply.started":"2025-08-24T20:32:20.428510Z","shell.execute_reply":"2025-08-24T20:32:20.444482Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"def Alk_Phos_Corr(dataset):\n    # Ensure types\n    dataset['Stage'] = pd.to_numeric(dataset['Stage'], errors='coerce')\n    dataset['Status'] = dataset['Status'].astype('category')\n\n    feat = 'Alk_Phos'\n\n    print('Missing count:', dataset[feat].isna().sum())\n    print('By Stage describe:\\n', dataset.groupby('Stage')[feat].describe())\n    print('By Status describe:\\n', dataset.groupby('Status')[feat].describe())\n\n    # Boxplots across Stage\n    plt.figure(figsize=(8, 5))\n    dataset.boxplot(column=feat, by='Stage')\n    plt.title(f'{feat} by Stage')\n    plt.suptitle('')\n    plt.xlabel('Stage')\n    plt.ylabel(feat)\n    plt.show()\n\n    # Boxplots across Status\n    plt.figure(figsize=(6, 5))\n    dataset.boxplot(column=feat, by='Status')\n    plt.title(f'{feat} by Status')\n    plt.suptitle('')\n    plt.xlabel('Status')\n    plt.ylabel(feat)\n    plt.show()\n\n    # Nonparametric tests (multi-group)\n    # Kruskal-Wallis: Stage (treat as groups)\n    stage_groups = [g[feat].dropna().values for _, g in dataset.groupby('Stage')]\n    kw_stat, kw_p = stats.kruskal(*stage_groups)\n    print(f'Kruskal–Wallis {feat} ~ Stage: stat={kw_stat:.3f}, p={kw_p:.4g}')\n\n    # If Stage is ordinal, also check monotonic trend via Spearman\n    spr_r, spr_p = stats.spearmanr(dataset['Stage'], dataset[feat], nan_policy='omit')\n    print(f'Spearman(Stage, {feat}): r={spr_r:.3f}, p={spr_p:.4g}')\n\n    # Kruskal–Wallis for Status (categorical)\n    status_groups = [g[feat].dropna().values for _, g in dataset.groupby('Status')]\n    kw_stat_s, kw_p_s = stats.kruskal(*status_groups)\n    print(f'Kruskal–Wallis {feat} ~ Status: stat={kw_stat_s:.3f}, p={kw_p_s:.4g}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.445740Z","iopub.execute_input":"2025-08-24T20:32:20.445942Z","iopub.status.idle":"2025-08-24T20:32:20.468915Z","shell.execute_reply.started":"2025-08-24T20:32:20.445918Z","shell.execute_reply":"2025-08-24T20:32:20.468167Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def Alk_Phos_Boxcox_log(dataset):\n    # Make safe positive array for Box-Cox\n    x = dataset['Alk_Phos'].dropna().values\n\n    # Box-Cox\n    x_bc, lam = stats.boxcox(x)\n    dataset.loc[dataset['Alk_Phos'].notna(), 'Alk_Phos_boxcox'] = x_bc\n    print(f'Box-Cox lambda for Alk_Phos: {lam:.4f}')\n\n    # Log1p\n    dataset['Alk_Phos_log1p'] = np.log1p(dataset['Alk_Phos'])\n\n    # Compare skewness\n    sk_raw = stats.skew(dataset['Alk_Phos'].dropna())\n    sk_bc = stats.skew(dataset['Alk_Phos_boxcox'].dropna())\n    sk_log = stats.skew(dataset['Alk_Phos_log1p'].dropna())\n    print(f'Skew raw={sk_raw:.3f}, boxcox={sk_bc:.3f}, log1p={sk_log:.3f}')\n\n    # box plots for transformed features\n    for col in ['Alk_Phos_boxcox', 'Alk_Phos_log1p']:\n        plt.figure(figsize=(8, 5))\n        dataset.boxplot(column=col, by='Stage')\n        plt.title(f'{col} by Stage')\n        plt.suptitle('')\n        plt.xlabel('Stage')\n        plt.ylabel(col)\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.469746Z","iopub.execute_input":"2025-08-24T20:32:20.469964Z","iopub.status.idle":"2025-08-24T20:32:20.489936Z","shell.execute_reply.started":"2025-08-24T20:32:20.469945Z","shell.execute_reply":"2025-08-24T20:32:20.489427Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def Alk_Phos_outliers(dataset, col):\n    q99 = dataset[col].quantile(0.99)\n    late_stage_cut = dataset['Stage'].quantile(0.75)  # top quartile of Stage considered \"late\"\n    is_extreme = dataset[col] >= q99\n    is_late = dataset['Stage'] >= late_stage_cut\n\n    tab = pd.crosstab(is_extreme, is_late, dropna=False)\n    print('Extreme vs Late-stage contingency:\\n', tab)\n    late_share = (is_extreme & is_late).sum() / is_extreme.sum() if is_extreme.sum() else 0\n    print(f'Share of extreme values in late stage: {late_share:.1%}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.490574Z","iopub.execute_input":"2025-08-24T20:32:20.490806Z","iopub.status.idle":"2025-08-24T20:32:20.515538Z","shell.execute_reply.started":"2025-08-24T20:32:20.490785Z","shell.execute_reply":"2025-08-24T20:32:20.514999Z"}},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"**SGOT**","metadata":{}},{"cell_type":"code","source":"def SGOT_Analysis(dataset, target=\"Status\"):\n    dataset['SGOT_missing'] = dataset['SGOT'].isna().astype(int) # Missing flag\n\n    # Median imputation grouped by Stage\n    dataset['SGOT'] = dataset.groupby('Stage')['SGOT'].transform(\n        lambda x: x.fillna(x.median())\n    )\n\n    # Outliers before transform\n    # outliers_check(dataset, \"SGOT\")\n\n    # Transformations\n    dataset, log_col = log_transform(dataset, \"SGOT\", False)\n    # dataset, boxcox_col, _ = boxcox_transform(dataset, \"SGOT\", False)\n\n    # Association tests for both versions\n    # for col in [log_col, boxcox_col]:\n    #     groups = [dataset.loc[dataset[target]==t, col] for t in dataset[target].unique()]\n    #     stat, p = stats.kruskal(*groups)\n    #     print(f\"Kruskal-Wallis for {col} vs {target}: stat={stat:.3f}, p={p:.4e}\")\n    #     outliers_check(dataset, col)\n\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.516272Z","iopub.execute_input":"2025-08-24T20:32:20.516497Z","iopub.status.idle":"2025-08-24T20:32:20.533044Z","shell.execute_reply.started":"2025-08-24T20:32:20.516483Z","shell.execute_reply":"2025-08-24T20:32:20.532345Z"}},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":"**Tryglicerides**","metadata":{}},{"cell_type":"code","source":"def Tryglicerides_Analysis(dataset, target=\"Status\"):\n    dataset['Tryglicerides_missing'] = dataset['Tryglicerides'].isna().astype(int) # Missing flag\n\n    # Median imputation grouped by Stage\n    dataset['Tryglicerides'] = dataset.groupby('Stage')['Tryglicerides'].transform(\n        lambda x: x.fillna(x.median())\n    )\n    # outliers_check(dataset, \"Tryglicerides\")\n\n    # Transformation\n    dataset, log_col = log_transform(dataset, \"Tryglicerides\", False)\n\n    # Association with target\n    # groups = [dataset.loc[dataset[target] == t, log_col] for t in dataset[target].unique()]\n    # stat, p = stats.kruskal(*groups)\n    # print(f\"Kruskal-Wallis for {log_col} vs {target}: stat={stat:.3f}, p={p:.4e}\")\n    # outliers_check(dataset, log_col)\n\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.533806Z","iopub.execute_input":"2025-08-24T20:32:20.534007Z","iopub.status.idle":"2025-08-24T20:32:20.553406Z","shell.execute_reply.started":"2025-08-24T20:32:20.533992Z","shell.execute_reply":"2025-08-24T20:32:20.552578Z"}},"outputs":[],"execution_count":85},{"cell_type":"markdown","source":"**Platelets**","metadata":{}},{"cell_type":"code","source":"def Platelets_Analysis(dataset, target=\"Status\"):\n    # Missing flag\n    dataset['Platelets_missing'] = dataset['Platelets'].isna().astype(int)\n\n    # Impute by Stage median\n    dataset['Platelets'] = dataset.groupby('Stage')['Platelets'].transform(\n        lambda x: x.fillna(x.median())\n    )\n\n    # Outlier check\n    # outliers_check(dataset, \"Platelets\")\n\n    # Transform\n    # dataset, log_col = log_transform(dataset, \"Platelets\")\n    dataset, boxcox_col, _ = boxcox_transform(dataset, \"Platelets\", False)\n\n    # Association test\n    # for col in [\"Platelets\", log_col, boxcox_col]:\n    #     groups = [dataset.loc[dataset[target]==t, col] for t in dataset[target].unique()]\n    #     stat, p = stats.kruskal(*groups)\n    #     print(f\"Kruskal-Wallis for {col} vs {target}: stat={stat:.3f}, p={p:.4e}\")\n\n    # outliers_check(dataset, log_col)\n    # outliers_check(dataset, boxcox_col)\n\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.554616Z","iopub.execute_input":"2025-08-24T20:32:20.554846Z","iopub.status.idle":"2025-08-24T20:32:20.569764Z","shell.execute_reply.started":"2025-08-24T20:32:20.554818Z","shell.execute_reply":"2025-08-24T20:32:20.569224Z"}},"outputs":[],"execution_count":86},{"cell_type":"markdown","source":"**Prothrombin**","metadata":{}},{"cell_type":"code","source":"def Prothrombin_Analysis(dataset, target=\"Status\"):\n    dataset['Prothrombin_missing'] = dataset['Prothrombin'].isna().astype(int) # Missing Flag\n\n    # Impute with Stage median\n    dataset['Prothrombin'] = dataset.groupby('Stage')['Prothrombin'].transform(\n        lambda x: x.fillna(x.median())\n    )\n    # outliers_check(dataset, 'Prothrombin')\n    dataset, col = log_transform(dataset, \"Prothrombin\", False)\n    # outliers_check(dataset, col)\n\n    # Association with target\n    # groups = [dataset.loc[dataset[target]==t, col] for t in dataset[target].unique()]\n    # stat, p = stats.kruskal(*groups)\n    # print(f\"Kruskal-Wallis for {col} vs {target}: stat={stat:.3f}, p={p:.4e}\")\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.570615Z","iopub.execute_input":"2025-08-24T20:32:20.571492Z","iopub.status.idle":"2025-08-24T20:32:20.594015Z","shell.execute_reply.started":"2025-08-24T20:32:20.571468Z","shell.execute_reply":"2025-08-24T20:32:20.593369Z"}},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"**Stage**","metadata":{}},{"cell_type":"code","source":"def Stage_Analysis(dataset):\n    # outliers_check(dataset, 'Stage')\n    # print(dataset['Stage'].value_counts())\n\n    # Correlation with Target\n    # corr, p = spearmanr(dataset['Stage'], dataset['Status'])\n    # print(\"Spearman correlation:\", corr, \"p-value:\", p)\n\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.594731Z","iopub.execute_input":"2025-08-24T20:32:20.594906Z","iopub.status.idle":"2025-08-24T20:32:20.611985Z","shell.execute_reply.started":"2025-08-24T20:32:20.594893Z","shell.execute_reply":"2025-08-24T20:32:20.611483Z"}},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":"**Status (Target)**","metadata":{}},{"cell_type":"code","source":"def Status_Analysis(dataset):\n    dataset = label_encoding(dataset, 'Status')\n    # print(dataset['Status'].value_counts())\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.612580Z","iopub.execute_input":"2025-08-24T20:32:20.612800Z","iopub.status.idle":"2025-08-24T20:32:20.629717Z","shell.execute_reply.started":"2025-08-24T20:32:20.612786Z","shell.execute_reply":"2025-08-24T20:32:20.629006Z"}},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"# Features and splitting","metadata":{}},{"cell_type":"markdown","source":"**Initialize Seed**","metadata":{}},{"cell_type":"code","source":"SEED = 42 # For reproducability\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.630473Z","iopub.execute_input":"2025-08-24T20:32:20.630654Z","iopub.status.idle":"2025-08-24T20:32:20.652562Z","shell.execute_reply.started":"2025-08-24T20:32:20.630640Z","shell.execute_reply":"2025-08-24T20:32:20.651963Z"}},"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fb2d6480d10>"},"metadata":{}}],"execution_count":90},{"cell_type":"markdown","source":"**Split train/validation/test**","metadata":{}},{"cell_type":"code","source":"# Train dataset\nX = train_dataset.drop(columns=['Status', 'id'])\ny = train_dataset[\"Status\"]\n\n# Test dataset\nx_test_data = test_df.drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.653179Z","iopub.execute_input":"2025-08-24T20:32:20.653418Z","iopub.status.idle":"2025-08-24T20:32:20.672856Z","shell.execute_reply.started":"2025-08-24T20:32:20.653393Z","shell.execute_reply":"2025-08-24T20:32:20.672093Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.673661Z","iopub.execute_input":"2025-08-24T20:32:20.673851Z","iopub.status.idle":"2025-08-24T20:32:20.700281Z","shell.execute_reply.started":"2025-08-24T20:32:20.673836Z","shell.execute_reply":"2025-08-24T20:32:20.699569Z"}},"outputs":[],"execution_count":92},{"cell_type":"markdown","source":"# Datasets Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Imputing**","metadata":{}},{"cell_type":"code","source":"# Fit imputers on train\nx_train_imputed, num_imputer, cat_imputer_dict = fit_predictive_imputer(x_train)\n\n# Transform validation\nx_val_imputed = transform_predictive_imputer(x_val, num_imputer, cat_imputer_dict)\n\n# Transform test dataset\nx_test_imputed = transform_predictive_imputer(x_test_data, num_imputer, cat_imputer_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:32:20.700917Z","iopub.execute_input":"2025-08-24T20:32:20.701138Z","iopub.status.idle":"2025-08-24T20:36:42.098888Z","shell.execute_reply.started":"2025-08-24T20:32:20.701099Z","shell.execute_reply":"2025-08-24T20:36:42.098242Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":93},{"cell_type":"markdown","source":"**Dataframe conversion**","metadata":{}},{"cell_type":"code","source":"# Columns of features\nfeature_cols = x_train.columns\n\n# Convert imputed arrays to DataFrames\nx_train_df = pd.DataFrame(x_train_imputed, columns=feature_cols, index=x_train.index)\nx_val_df   = pd.DataFrame(x_val_imputed, columns=feature_cols, index=x_val.index)\n\n# Combine with target\ntrain_dataset = pd.concat([x_train_df, y_train], axis=1)\nval_dataset   = pd.concat([x_val_df, y_val], axis=1)\n\n# For test dataset\ntest_dataset = pd.DataFrame(x_test_imputed, columns=feature_cols, index=x_test_data.index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.099778Z","iopub.execute_input":"2025-08-24T20:36:42.099998Z","iopub.status.idle":"2025-08-24T20:36:42.109414Z","shell.execute_reply.started":"2025-08-24T20:36:42.099980Z","shell.execute_reply":"2025-08-24T20:36:42.108789Z"}},"outputs":[],"execution_count":94},{"cell_type":"markdown","source":"**Apply analysis on features**","metadata":{}},{"cell_type":"code","source":"# def analysis(dataset, train):\n#     dataset = Drug_Analysis(dataset)\n#     dataset = Age_Analysis(dataset)\n#     dataset = Sex_Analysis(dataset)\n#     dataset = Ascites_Analysis(dataset)\n#     dataset = Hepatomegaly_Analysis(dataset)\n#     dataset = Spiders_Analysis(dataset)\n#     dataset = Edema_Analysis(dataset)\n#     dataset = Bilirubin_Analysis(dataset)\n#     dataset = Albumin_Analysis(dataset)\n#     dataset = Cholesterol_Analysis(dataset)\n#     dataset = Copper_Analysis(dataset)\n#     dataset = AlkPhos_Analysis(dataset)  \n#     dataset = AlkPhos_Analysis(dataset)\n#     dataset = Copper_Analysis(dataset)\n#     dataset = Cholesterol_Analysis(dataset)\n#     dataset = SGOT_Analysis(dataset)\n#     dataset = Tryglicerides_Analysis(dataset)\n#     dataset = Platelets_Analysis(dataset)\n#     dataset = Prothrombin_Analysis(dataset)  t \n#     if train:\n#         dataset = Status_Analysis(dataset)\n\n#     return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.110429Z","iopub.execute_input":"2025-08-24T20:36:42.110673Z","iopub.status.idle":"2025-08-24T20:36:42.123497Z","shell.execute_reply.started":"2025-08-24T20:36:42.110650Z","shell.execute_reply":"2025-08-24T20:36:42.122979Z"}},"outputs":[],"execution_count":95},{"cell_type":"markdown","source":"**Call all analysis**","metadata":{}},{"cell_type":"code","source":"# # Train preprocessing\n# train_dataset = analysis(train_df, True)\n# validation_dataset = analysis(val_df, False)\n\n# # Test preprocessing\n# test_dataset = analysis(test_df, False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.124126Z","iopub.execute_input":"2025-08-24T20:36:42.124372Z","iopub.status.idle":"2025-08-24T20:36:42.144958Z","shell.execute_reply.started":"2025-08-24T20:36:42.124356Z","shell.execute_reply":"2025-08-24T20:36:42.144463Z"}},"outputs":[],"execution_count":96},{"cell_type":"markdown","source":"**Boxcox transformation**","metadata":{}},{"cell_type":"code","source":"# cols = [\"Platelets\", \"Alk_Phos\", \"Copper\", \"Albumin\", \"Cholesterol\", \"Bilirubin\", \"Bilirubin\", \"Age\"]\n# # Training set\n# train_dataset, lambdas, shifts = boxcox_train(train_dataset, cols)\n\n# # Validation set\n# val_dataset = boxcox_apply(val_dataset, cols, lambdas, shifts)\n\n# # Test set\n# test_dataset = boxcox_apply(test_dataset, cols, lambdas, shifts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.145869Z","iopub.execute_input":"2025-08-24T20:36:42.146129Z","iopub.status.idle":"2025-08-24T20:36:42.165666Z","shell.execute_reply.started":"2025-08-24T20:36:42.146108Z","shell.execute_reply":"2025-08-24T20:36:42.165136Z"}},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":"**Log transformation**","metadata":{}},{"cell_type":"code","source":"# log_cols = ['SGOT', 'Prothrombin', 'Tryglicerides']\n# train_dataset, val_dataset, test_dataset = log_transform(\n#     train_dataset, val_dataset, test_dataset, log_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.166273Z","iopub.execute_input":"2025-08-24T20:36:42.166453Z","iopub.status.idle":"2025-08-24T20:36:42.182412Z","shell.execute_reply.started":"2025-08-24T20:36:42.166440Z","shell.execute_reply":"2025-08-24T20:36:42.181860Z"}},"outputs":[],"execution_count":98},{"cell_type":"markdown","source":"**One hot encoding**","metadata":{}},{"cell_type":"code","source":"# Fill the single value in Hepatomegaly \ntrain_dataset['Hepatomegaly'] = train_dataset['Hepatomegaly'].replace(\n    'S', train_dataset['Hepatomegaly'].mode()[0])\n\ncat_cols = ['Spiders', 'Hepatomegaly', 'Ascites', 'Sex', 'Drug', 'Edema']\n\ntrain_dataset = one_hot_encoding(train_dataset, cat_cols)\nval_dataset   = one_hot_encoding(val_dataset, cat_cols)\ntest_dataset  = one_hot_encoding(test_dataset, cat_cols)\n\n# Make sure val/test match train columns\nval_dataset  = val_dataset.reindex(columns=train_dataset.columns, fill_value=0)\ntest_dataset = test_dataset.reindex(columns=train_dataset.columns, fill_value=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.182979Z","iopub.execute_input":"2025-08-24T20:36:42.183163Z","iopub.status.idle":"2025-08-24T20:36:42.236369Z","shell.execute_reply.started":"2025-08-24T20:36:42.183148Z","shell.execute_reply":"2025-08-24T20:36:42.235604Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_8851/918165853.py:2: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n  train_dataset['Hepatomegaly'] = train_dataset['Hepatomegaly'].replace(\n","output_type":"stream"}],"execution_count":99},{"cell_type":"markdown","source":"**Label Encoding**","metadata":{}},{"cell_type":"code","source":"# Target encoding\ntrain_dataset, val_dataset = label_encoding(train_dataset, val_dataset, \"Status\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.237221Z","iopub.execute_input":"2025-08-24T20:36:42.237874Z","iopub.status.idle":"2025-08-24T20:36:42.243507Z","shell.execute_reply.started":"2025-08-24T20:36:42.237850Z","shell.execute_reply":"2025-08-24T20:36:42.242775Z"}},"outputs":[],"execution_count":100},{"cell_type":"markdown","source":"**Sampling**","metadata":{}},{"cell_type":"code","source":"# # Split\n# majority = train_dataset[train_dataset.Status == 0]\n# medium   = train_dataset[train_dataset.Status == 2]\n# minority = train_dataset[train_dataset.Status == 1]\n\n# # Upsample minority and medium to match majority\n# medium_upsampled   = resample(medium,   replace=True, n_samples=len(majority), random_state=SEED)\n# minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=SEED)\n\n# # Combine\n# train_balanced = pd.concat([majority, medium_upsampled, minority_upsampled])\n\n# x_train_balanced = train_balanced.drop(columns=\"Status\")\n# y_train_balanced = train_balanced[\"Status\"]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.244326Z","iopub.execute_input":"2025-08-24T20:36:42.244636Z","iopub.status.idle":"2025-08-24T20:36:42.263624Z","shell.execute_reply.started":"2025-08-24T20:36:42.244612Z","shell.execute_reply":"2025-08-24T20:36:42.263079Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"x_train_dataset = train_dataset.drop(columns=\"Status\")\ny_train_dataset = train_dataset[\"Status\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.264290Z","iopub.execute_input":"2025-08-24T20:36:42.264484Z","iopub.status.idle":"2025-08-24T20:36:42.282641Z","shell.execute_reply.started":"2025-08-24T20:36:42.264468Z","shell.execute_reply":"2025-08-24T20:36:42.281947Z"}},"outputs":[],"execution_count":102},{"cell_type":"markdown","source":"**Feature scaling**","metadata":{}},{"cell_type":"code","source":"# Split val_df\nx_val = val_dataset.drop(columns=\"Status\")\ny_val = val_dataset[\"Status\"]\n\nscaler = StandardScaler()\n# Fit on train features\nx_train_scaled = scaler.fit_transform(x_train_dataset)\n\n# Ensure val and test have the same feature columns as train\nx_val_scaled   = scaler.transform(x_val[x_train_dataset.columns])\nx_test_scaled  = scaler.transform(test_dataset.reindex(columns=x_train_dataset.columns, fill_value=0))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.283366Z","iopub.execute_input":"2025-08-24T20:36:42.283646Z","iopub.status.idle":"2025-08-24T20:36:42.315153Z","shell.execute_reply.started":"2025-08-24T20:36:42.283628Z","shell.execute_reply":"2025-08-24T20:36:42.314600Z"}},"outputs":[],"execution_count":103},{"cell_type":"markdown","source":"# Train the model and predict","metadata":{}},{"cell_type":"markdown","source":"**Dataset wrapper**","metadata":{}},{"cell_type":"code","source":"class CirrhosisDataset(Dataset):\n    def __init__(self, X, y):\n        if hasattr(X, \"values\"): X = X.values\n        if hasattr(y, \"values\"): y = y.values\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:36:42.315945Z","iopub.execute_input":"2025-08-24T20:36:42.316214Z","iopub.status.idle":"2025-08-24T20:36:42.321062Z","shell.execute_reply.started":"2025-08-24T20:36:42.316173Z","shell.execute_reply":"2025-08-24T20:36:42.320349Z"}},"outputs":[],"execution_count":104},{"cell_type":"markdown","source":"**Neural network architecture**","metadata":{}},{"cell_type":"code","source":"class NeuralNetwork(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(NeuralNetwork, self).__init__()\n        self.network = nn.Sequential(\n        nn.Linear(input_dim, 64),\n        nn.BatchNorm1d(64),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n    \n        nn.Linear(64, 32),\n        nn.BatchNorm1d(32),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n    \n        nn.Linear(32, num_classes)\n    )\n\n\n    def forward(self, x):\n        return self.network(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:41:27.595358Z","iopub.execute_input":"2025-08-24T20:41:27.595678Z","iopub.status.idle":"2025-08-24T20:41:27.600934Z","shell.execute_reply.started":"2025-08-24T20:41:27.595656Z","shell.execute_reply":"2025-08-24T20:41:27.600218Z"}},"outputs":[],"execution_count":111},{"cell_type":"markdown","source":"**Model training**","metadata":{}},{"cell_type":"code","source":"def train_evaluate_nn(x_train_scaled, y_train, \n                      x_val_scaled, y_val, \n                      x_test_scaled,\n                      num_classes=3, num_epochs=300, batch_size=64,\n                      lr=0.001, weight_decay=0.00001, patience=50):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    # Datasets & Loaders\n    train_loader = DataLoader(CirrhosisDataset(x_train_scaled, y_train),\n                              batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(CirrhosisDataset(x_val_scaled, y_val),\n                            batch_size=batch_size, shuffle=False)\n\n    # Model\n    model = NeuralNetwork(x_train_scaled.shape[1], num_classes).to(device)\n\n    # Class weights (handles imbalance)\n    classes = np.unique(y_train)\n    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n\n    # Optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n\n    # OneCycleLR Scheduler (10x base lr)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        max_lr=lr * 10,\n        steps_per_epoch=len(train_loader),\n        epochs=num_epochs,\n        pct_start=0.3,\n        anneal_strategy=\"cos\"\n    )\n\n    best_loss = float('inf')\n    counter = 0\n\n    for epoch in range(num_epochs):\n        # --- Training ---\n        model.train()\n        train_loss = 0\n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(X_batch), y_batch)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()  # step per batch (important for OneCycleLR)\n            train_loss += loss.item()\n        avg_train = train_loss / len(train_loader)\n\n        # --- Validation ---\n        model.eval()\n        val_loss, correct, total = 0, 0, 0\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n                val_loss += criterion(outputs, y_batch).item()\n                preds = outputs.argmax(dim=1)\n                correct += (preds == y_batch).sum().item()\n                total += y_batch.size(0)\n\n        avg_val = val_loss / len(val_loader)\n        val_acc = correct / total if total > 0 else 0.0\n\n        # Logging\n        if (epoch + 1) % 10 == 0 or epoch == 0:\n            current_lr = optimizer.param_groups[0]['lr']\n            print(f\"Epoch {epoch+1:03d}, LR: {current_lr:.6f}, \"\n                  f\"Train Loss: {avg_train:.4f}, Val Loss: {avg_val:.4f}, Val Acc: {val_acc:.4f}\")\n\n        # Early stopping\n        if avg_val < best_loss:\n            best_loss = avg_val\n            torch.save(model.state_dict(), \"best_model.pth\")\n            counter = 0\n        else:\n            counter += 1\n            if counter >= patience:\n                print(\"Early stopping triggered\")\n                break\n\n    # Reload best model\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n    return model, device\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:41:27.604846Z","iopub.execute_input":"2025-08-24T20:41:27.605041Z","iopub.status.idle":"2025-08-24T20:41:27.623666Z","shell.execute_reply.started":"2025-08-24T20:41:27.605026Z","shell.execute_reply":"2025-08-24T20:41:27.623095Z"}},"outputs":[],"execution_count":112},{"cell_type":"markdown","source":"**Training and predictions**","metadata":{}},{"cell_type":"code","source":"model, device = train_evaluate_nn(x_train_scaled, y_train_dataset, x_val_scaled, y_val, x_test_scaled)","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-08-24T20:41:27.624728Z","iopub.execute_input":"2025-08-24T20:41:27.624964Z","iopub.status.idle":"2025-08-24T20:42:05.471429Z","shell.execute_reply.started":"2025-08-24T20:41:27.624943Z","shell.execute_reply":"2025-08-24T20:42:05.470670Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 001, LR: 0.000403, Train Loss: 1.0137, Val Loss: 0.9100, Val Acc: 0.7658\nEpoch 010, LR: 0.000690, Train Loss: 0.7716, Val Loss: 0.7475, Val Acc: 0.6971\nEpoch 020, LR: 0.001523, Train Loss: 0.7526, Val Loss: 0.7523, Val Acc: 0.7398\nEpoch 030, LR: 0.002800, Train Loss: 0.7159, Val Loss: 0.7636, Val Acc: 0.7402\nEpoch 040, LR: 0.004367, Train Loss: 0.7108, Val Loss: 0.7529, Val Acc: 0.7253\nEpoch 050, LR: 0.006034, Train Loss: 0.7152, Val Loss: 0.7542, Val Acc: 0.7380\nEpoch 060, LR: 0.007601, Train Loss: 0.7038, Val Loss: 0.7505, Val Acc: 0.7116\nEpoch 070, LR: 0.008878, Train Loss: 0.6992, Val Loss: 0.7891, Val Acc: 0.6976\nEpoch 080, LR: 0.009711, Train Loss: 0.6897, Val Loss: 0.7959, Val Acc: 0.7700\nEarly stopping triggered\n","output_type":"stream"}],"execution_count":113},{"cell_type":"markdown","source":"**Test set prediction**","metadata":{}},{"cell_type":"code","source":"def test_set_prediction(model, x_test, device):\n    model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n    model.eval()\n    with torch.no_grad():\n        test_tensor = torch.tensor(x_test, dtype=torch.float32).to(device)\n        y_prob = torch.softmax(model(test_tensor), dim=1).cpu().numpy()\n        # Clip probabilities to avoid extreme log-loss\n        y_prob = np.clip(y_prob, 1e-3, 1 - 1e-3)\n\n    return y_prob","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:42:05.472174Z","iopub.execute_input":"2025-08-24T20:42:05.472513Z","iopub.status.idle":"2025-08-24T20:42:05.477180Z","shell.execute_reply.started":"2025-08-24T20:42:05.472483Z","shell.execute_reply":"2025-08-24T20:42:05.476565Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"y_prob_submission = test_set_prediction(model, x_test_scaled, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:42:05.478528Z","iopub.execute_input":"2025-08-24T20:42:05.478968Z","iopub.status.idle":"2025-08-24T20:42:05.504001Z","shell.execute_reply.started":"2025-08-24T20:42:05.478945Z","shell.execute_reply":"2025-08-24T20:42:05.503478Z"}},"outputs":[],"execution_count":115},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_df['id'],\n    'Status_C': y_prob_submission[:, 0],\n    'Status_CL': y_prob_submission[:, 1],\n    'Status_D': y_prob_submission[:, 2]\n})\n\nsubmission.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"Submission file saved successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T20:42:05.505220Z","iopub.execute_input":"2025-08-24T20:42:05.505435Z","iopub.status.idle":"2025-08-24T20:42:05.552868Z","shell.execute_reply.started":"2025-08-24T20:42:05.505419Z","shell.execute_reply":"2025-08-24T20:42:05.552353Z"}},"outputs":[{"name":"stdout","text":"Submission file saved successfully\n","output_type":"stream"}],"execution_count":116}]}